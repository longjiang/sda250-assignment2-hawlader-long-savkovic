{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb56157",
   "metadata": {},
   "source": [
    "|   Name (Last, First)   |   Student ID   |   Section contributed                                          |   Section edited                                   |   Other contributions                                                      |\n",
    "|------------------------|----------------|----------------------------------------------------------------|----------------------------------------------------|----------------------------------------------------------------------------|\n",
    "|    Jiang Long          |    200099436   |   -  |   -                                     |   -  |\n",
    "|    Antanila H.         |    301332035   |   -         |   -   |   -     |\n",
    "|    Sava Savkovic       |    301397121   |   -                                |   -                                     |   -     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27fc33dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import math\n",
    "import nltk\n",
    "\n",
    "max_documents = 10000 # 'None' means no limit. Tokenizing all 485,212 reviews will take a LONG TIME\n",
    "\n",
    "# The dataset CSV is from https://www.kaggle.com/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset\n",
    "# We truncate the CSV so it's less than 100 MB (GitHub's file size limit)\n",
    "# The truncated CSV contains 485,212 movie reviews from Rotten Tomatoes, each labeled 'Fresh' (positive) or 'Rotten' (negative)\n",
    "file_path = 'rotten-tomatoes-movies-and-critic-reviews-dataset/rotten_tomatoes_critic_reviews.csv'\n",
    "\n",
    "# Open the file again for reading\n",
    "f = open(file_path, encoding='UTF8')\n",
    "csv_reader = csv.DictReader(f)\n",
    "\n",
    "documents = []\n",
    "documents_text = ''\n",
    "\n",
    "for line in itertools.islice(csv_reader, 0, max_documents):\n",
    "    # For some reason '10,000' shows up as an \"informative feature\", let's ignore comments with it\n",
    "    if \"10,000\" in line['review_content']: \n",
    "        continue\n",
    "    if(line['review_type']):\n",
    "        sentiment = False\n",
    "        if line['review_type'] == 'Fresh':\n",
    "            sentiment = 'pos'\n",
    "        if line['review_type'] == 'Rotten':\n",
    "            sentiment = 'neg'\n",
    "        if(sentiment):\n",
    "            tokens = nltk.word_tokenize(line['review_content'])\n",
    "            documents_text = documents_text + line['review_content']\n",
    "            documents.append((tokens, sentiment))\n",
    "\n",
    "documents_tokens = nltk.word_tokenize(documents_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5995a4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_word_features = 2000\n",
    "\n",
    "all_words = nltk.FreqDist(w.lower() for w in documents_tokens)\n",
    "word_features = list(all_words)[:max_word_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bb1d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "featuresets = [(document_features(d), c) for (d,c) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0625c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_ratio = 0.9 # 0.9 means 90% of the data is for training, 10% is for testing\n",
    "\n",
    "train_set_size = math.floor(len(documents) * train_set_ratio)\n",
    "\n",
    "train_set, test_set = featuresets[:train_set_size], featuresets[train_set_size:]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32f0c332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6930792377131394\n",
      "Most Informative Features\n",
      "       contains(unfunny) = True              neg : pos    =     17.4 : 1.0\n",
      "     contains(immigrant) = True              pos : neg    =     15.9 : 1.0\n",
      "   contains(beautifully) = True              pos : neg    =     11.4 : 1.0\n",
      "         contains(worst) = True              neg : pos    =     11.0 : 1.0\n",
      "     contains(absorbing) = True              pos : neg    =     10.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Test the classifier\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "# Show the most important features as interpreted by Naive Bayes\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55778c32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
